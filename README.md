# Databricks Multi-Agent System

A sophisticated multi-agent architecture for Databricks data engineering tasks, powered by local LLMs (Ollama) with specialized agents for different domains.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Streamlit UI                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Orchestrator Agent                              â”‚
â”‚  â€¢ Routes queries to specialized agents                             â”‚
â”‚  â€¢ Manages conversation context                                      â”‚
â”‚  â€¢ Coordinates multi-agent workflows                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚          â”‚
       â–¼          â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Schema  â”‚â”‚   SQL    â”‚â”‚ Pipeline â”‚â”‚ Metadata â”‚â”‚   Chat   â”‚
â”‚  Agent   â”‚â”‚  Agent   â”‚â”‚  Agent   â”‚â”‚  Agent   â”‚â”‚  Agent   â”‚
â”‚          â”‚â”‚          â”‚â”‚          â”‚â”‚          â”‚â”‚          â”‚
â”‚â€¢ DDL Gen â”‚â”‚â€¢ Query   â”‚â”‚â€¢ DLT     â”‚â”‚â€¢ Tags    â”‚â”‚â€¢ Q&A     â”‚
â”‚â€¢ Alter   â”‚â”‚â€¢ Optimizeâ”‚â”‚â€¢ Stream  â”‚â”‚â€¢ Commentsâ”‚â”‚â€¢ Explain â”‚
â”‚â€¢ Infer   â”‚â”‚â€¢ Debug   â”‚â”‚â€¢ Bronze/ â”‚â”‚â€¢ Props   â”‚â”‚â€¢ Best    â”‚
â”‚          â”‚â”‚          â”‚â”‚  Silver/ â”‚â”‚          â”‚â”‚  Practiceâ”‚
â”‚          â”‚â”‚          â”‚â”‚  Gold    â”‚â”‚          â”‚â”‚          â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚           â”‚           â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      Shared Tool Layer       â”‚
              â”‚  â€¢ Databricks SDK            â”‚
              â”‚  â€¢ SQL Execution             â”‚
              â”‚  â€¢ File Processing           â”‚
              â”‚  â€¢ Schema Inference          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     LLM Layer (Ollama)       â”‚
              â”‚  â€¢ llama3.1 / llama3.2       â”‚
              â”‚  â€¢ codellama                 â”‚
              â”‚  â€¢ mistral                   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸŒŸ Features

### Specialized Agents

| Agent | Responsibilities |
|-------|-----------------|
| **Orchestrator** | Routes queries, manages context, coordinates workflows |
| **Schema Agent** | DDL generation, ALTER statements, type inference |
| **SQL Agent** | Query optimization, debugging, performance tuning |
| **Pipeline Agent** | DLT pipelines, Bronze/Silver/Gold layers, streaming |
| **Metadata Agent** | Tags, comments, table properties, governance |
| **Chat Agent** | General Q&A, best practices, explanations |

### Key Capabilities

- ğŸ”„ **Intelligent Routing**: Automatically routes queries to the most appropriate agent
- ğŸ¤ **Agent Collaboration**: Agents can delegate tasks and share context
- ğŸ“Š **CSV to Table**: Upload CSV files and auto-generate DDL with type inference
- âš¡ **Delta Live Tables**: Generate Bronze/Silver/Gold pipeline code
- ğŸ·ï¸ **Metadata Management**: Comprehensive tagging and documentation
- ğŸ” **Query Optimization**: SQL analysis and performance recommendations

## ğŸ“ Project Structure

```
databricks-multiagent-system/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py             # Configuration management
â”‚   â””â”€â”€ prompts.yaml            # Agent prompt templates
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py           # Base agent class
â”‚   â”œâ”€â”€ orchestrator.py         # Main orchestrator agent
â”‚   â”œâ”€â”€ agent_registry.py       # Agent registration and discovery
â”‚   â””â”€â”€ message.py              # Message types and routing
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schema_agent.py         # Schema/DDL operations
â”‚   â”œâ”€â”€ sql_agent.py            # SQL query operations
â”‚   â”œâ”€â”€ pipeline_agent.py       # DLT pipeline generation
â”‚   â”œâ”€â”€ metadata_agent.py       # Metadata management
â”‚   â””â”€â”€ chat_agent.py           # General chat/Q&A
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ databricks_tools.py     # Databricks SDK wrapper
â”‚   â”œâ”€â”€ sql_tools.py            # SQL execution tools
â”‚   â”œâ”€â”€ file_tools.py           # File processing utilities
â”‚   â””â”€â”€ schema_tools.py         # Schema inference tools
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py           # Ollama client wrapper
â”‚   â”œâ”€â”€ validators.py           # Input validation
â”‚   â””â”€â”€ formatters.py           # Output formatting
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ orchestrator.txt        # Orchestrator system prompt
â”‚   â”œâ”€â”€ schema_agent.txt        # Schema agent prompt
â”‚   â”œâ”€â”€ sql_agent.txt           # SQL agent prompt
â”‚   â”œâ”€â”€ pipeline_agent.txt      # Pipeline agent prompt
â”‚   â”œâ”€â”€ metadata_agent.txt      # Metadata agent prompt
â”‚   â””â”€â”€ chat_agent.txt          # Chat agent prompt
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ components.py           # Reusable UI components
â”‚   â”œâ”€â”€ tabs.py                 # Tab implementations
â”‚   â””â”€â”€ styles.py               # Custom CSS styles
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agents.py          # Agent unit tests
â”‚   â”œâ”€â”€ test_tools.py           # Tool tests
â”‚   â””â”€â”€ test_orchestrator.py    # Orchestrator tests
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### Prerequisites

1. **Install Ollama**:
   ```bash
   curl -fsSL https://ollama.ai/install.sh | sh
   ```

2. **Pull a model**:
   ```bash
   ollama pull llama3.1
   ```

3. **Start Ollama server**:
   ```bash
   ollama serve
   ```

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repo-url>
   cd databricks-multiagent-system
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**:
   ```bash
   cp .env.example .env
   # Edit .env with your Databricks credentials
   ```

5. **Run the application**:
   ```bash
   streamlit run app.py
   ```

## âš™ï¸ Configuration

Create a `.env` file with the following variables:

```env
# Ollama Configuration
OLLAMA_MODEL=llama3.1
OLLAMA_BASE_URL=http://localhost:11434

# Databricks Configuration
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
DATABRICKS_TOKEN=your-token-here
DATABRICKS_CATALOG=main
DATABRICKS_SCHEMA=default
DATABRICKS_WAREHOUSE_ID=your-warehouse-id

# Agent Configuration
ORCHESTRATOR_MODEL=llama3.1
SPECIALIZED_AGENT_MODEL=llama3.1
MAX_AGENT_ITERATIONS=5
AGENT_TIMEOUT=120
```

## ğŸ”§ Usage Examples

### 1. Schema Operations
```
User: Create a customer table from this CSV file
â†’ Orchestrator routes to Schema Agent
â†’ Schema Agent infers types and generates DDL
â†’ Returns CREATE TABLE statement
```

### 2. Query Optimization
```
User: How can I optimize this slow query?
â†’ Orchestrator routes to SQL Agent
â†’ SQL Agent analyzes query and suggests improvements
â†’ Returns optimization recommendations
```

### 3. Pipeline Generation
```
User: Create a DLT pipeline for customer data
â†’ Orchestrator routes to Pipeline Agent
â†’ Pipeline Agent generates Bronze/Silver/Gold layers
â†’ Returns complete DLT Python code
```

### 4. Multi-Agent Workflow
```
User: Create a table from CSV, add PII tags, and create a DLT pipeline
â†’ Orchestrator coordinates multiple agents:
  1. Schema Agent creates DDL
  2. Metadata Agent adds tags
  3. Pipeline Agent generates DLT
â†’ Returns complete solution
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_agents.py

# Run with coverage
pytest --cov=. tests/
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“œ License

MIT License - See LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/)
- Powered by [Ollama](https://ollama.ai/)
- Uses [Databricks SDK](https://docs.databricks.com/dev-tools/sdk-python.html)
- LLM integration via [LangChain](https://www.langchain.com/)
